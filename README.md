# Confidence-Aware Imitation Learning (CARIL) for Autonomous Driving

This repository contains the official implementation of **CARIL: Confidence-Aware Regression in Imitation Learning for Autonomous Driving**. The project introduces a **dual-head neural network** combining **regression** and **classification** for end-to-end vision-based imitation  learning,which was submitted to **IROS 2025**. The classification head provides **confidence scores**, enabling a **correction mechanism** to improve driving stability in **uncertain situations**.

---

## ğŸ“‘ Table of Contents
1. [Key Contributions](#-key-contributions)
2. [Repository Structure](#-repository-structure)
3. [Prerequisites](#-prerequisites)
4. [Installation & Setup](#-installation--setup)
5. [Workflow Steps](#-workflow-steps)
6. [Running the Simulation](#-running-the-simulation)
7. [Active Inference Agent](#-active-inference-agent)
8. [Usage](#-usage)
9. [Troubleshooting](#-troubleshooting)
10. [Evaluation: Trajectory Similarity](#-evaluation-trajectory-similarity)
11. [Citation](#-citation)
12. [Contact](#-contact)
13. [Future Work](#-future-work)

---

## ğŸ”¥ Key Contributions
- **Dual-Head Architecture**: Combines **regression** for precise control and **classification** to estimate confidence.
- **Confidence-Aware Correction**: Applies real-time adjustments when confidence is low, improving driving stability.
- **Closed-Loop Evaluation**: Tested in **CARLA** using controlled scenarios with **predefined routes**.
- **Trajectory Similarity Analysis**: Uses **Frechet distance, Dynamic Time Warping (DTW), and Area Between Curves (ABC)** to assess path accuracy.

---

## ğŸ“‚ Repository Structure

```
Confidence_Aware_IL/
â”‚â”€â”€ Code/                      # Core scripts for training, evaluation, and model definition
â”‚   â”œâ”€â”€ data_loader.py         # Data loading functions
â”‚   â”œâ”€â”€ evaluate.py            # Evaluation script for testing performance
â”‚   â”œâ”€â”€ model.py               # Model architecture definition
â”‚   â”œâ”€â”€ train.py               # Training pipeline
â”‚
â”‚â”€â”€ Data Collection/           # Scripts for data collection and preprocessing
â”‚   â”œâ”€â”€ collect_data.py        # CARLA-based data collection script
â”‚   â”œâ”€â”€ preprocess_data.py     # Data normalization, augmentation, and scaling
â”‚
â”‚â”€â”€ Driving Evaluation/        # Scripts for testing and post-processing
â”‚   â”œâ”€â”€ Metric.py              # Metrics for evaluating similarity
â”‚   â”œâ”€â”€ postprocessing.py      # Post-processing trajectory data
â”‚   â”œâ”€â”€ test_scenario.py       # CARLA test scenario execution
â”‚
â”‚â”€â”€ results/                   # CSV logs for analysis
â”‚â”€â”€ pretrained_models/         # Directory containing pretrained models
â”‚â”€â”€ reference_data/            # Reference trajectory CSV files
â”‚â”€â”€ .gitignore                 # Ignore unnecessary files
â”‚â”€â”€ README.md                  # This file
```

---

## ğŸ”¹ Prerequisites
Before setting up the environment, ensure you have the following installed:
- **Ubuntu 20.04 LTS** (or compatible version)
- **CARLA Simulator** (version 0.9.13+ recommended)
- **Python 3.8+** (recommended via Anaconda environment)
- **Anaconda** (optional but recommended)
- **CUDA Toolkit 11.8** (for GPU support)
- **cuDNN 8.9** (for deep learning acceleration)
- **Git**

---

## ğŸ›  Installation & Setup

### **1ï¸âƒ£ Install CARLA Simulator**
CARIL is tested on **CARLA 0.9.15**. Follow the official setup guide:
```bash
# Download CARLA
wget https://carla-releases.s3.eu-west-3.amazonaws.com/Linux/CARLA_0.9.15.tar.gz
mkdir CARLA_0.9.15
cd CARLA_0.9.15

# Extract and Run
tar -xvzf ../CARLA_0.9.15.tar.gz
./CarlaUE4.sh
```

### **2ï¸âƒ£ Install Dependencies**
Run the following to install required Python packages:
```bash
pip install -r requirements.txt
```

---

## ğŸ”„ Workflow Steps

### **1ï¸âƒ£ Data Collection**
Collect driving data in CARLA using the data collection script:
```bash
python Data Collection/collect_data.py --town Town04
```

### **2ï¸âƒ£ Data Preprocessing**
Normalize, augment, and filter the collected data:
```bash
python Data Collection/preprocess_data.py --input_csv <path_to_input_csv> \
    --output_csv <path_to_output_csv> --input_dir <path_to_images> \
    --output_dir <output_directory>
```
#### **Preprocessing Arguments:**
- `--input_csv`: Path to input CSV file containing raw data.
- `--output_csv`: Path to save the processed CSV file.
- `--input_dir`: Directory containing the input images.
- `--output_dir`: Directory to store processed images and plots.

### **3ï¸âƒ£ Model Training**
Train the imitation learning model:
```bash
python Code/train.py --epochs 50 --batch_size 32 --learning_rate 0.0001 --save_model_path pretrained_models/final_trained_model.h5
```

### **4ï¸âƒ£ Model Evaluation**
Evaluate the trained model on the validation set:
```bash
python Code/evaluate.py
```

### **5ï¸âƒ£ Testing with CARLA**
Test the model in CARLA using predefined driving scenarios:
```bash
python Driving Evaluation/test_scenario.py --correction True
```
Logs are saved in `results/`.

### **6ï¸âƒ£ Post-Processing & Analysis**
Analyze trajectory similarity and performance metrics:
```bash
python Driving Evaluation/postprocessing.py
```

---

## ğŸ“œ Pretrained Models & Reference Data
- **Pretrained Model:** [Download Here](https://www.dropbox.com/scl/fi/njtnclwcga4sa01sm6aan/Pretrained_model.h5?rlkey=3csab4vz9l4dkh7tvir8hug9a&st=e6x4q9tb&dl=0)
- **Reference Trajectory Data:** [Download Here](https://www.dropbox.com/scl/fi/gjshtuld1p6va3try8q2z/reference_track.csv?rlkey=sgfcbe4p00qh5pqklg8dr5sul&st=fs5dn1gk&dl=0)

---

## ğŸ“œ Citation
If you use this repository, please cite:

```bibtex
@inproceedings{Delavari2025CARIL,
  author    = {Elahe Delavari and Aws Khalil and Jaerock Kwon},
  title     = {CARIL: Confidence-Aware Regression in Imitation Learning for Autonomous Driving},
  booktitle = {IROS},
  year      = {2025}
}
```

---

## ğŸ“¬ Contact
For questions, please contact [Elahe Delavari](mailto:elahed@umich.edu).

---

### ğŸš€ Future Work
- **Adaptive Confidence Thresholds** for varying road conditions.
- **Multi-modal Sensor Fusion** integrating LiDAR & radar.
- **Real-world deployment** beyond CARLA simulations.

---

